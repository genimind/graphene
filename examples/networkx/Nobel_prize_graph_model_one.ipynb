{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building graph using Nobel_prize JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "file1 = '../data/Nobel_prize.json'\n",
    "file2 = '../data/Nobel_laureate.json'\n",
    "file3 = '../data/Nobel_country.json' # this file has simple json structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file1) as json_file:\n",
    "    json_data1 = json.load(json_file)\n",
    "# json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.io.json import json_normalize\n",
    "\n",
    "# # this is not practical for the this json data\n",
    "# df = json_normalize(json_data1, 'prizes')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '960',\n",
       "  'firstname': 'Arthur',\n",
       "  'surname': 'Ashkin',\n",
       "  'motivation': '\"for the optical tweezers and their application to biological systems\"',\n",
       "  'share': '2'},\n",
       " {'id': '961',\n",
       "  'firstname': 'GÃ©rard',\n",
       "  'surname': 'Mourou',\n",
       "  'motivation': '\"for their method of generating high-intensity, ultra-short optical pulses\"',\n",
       "  'share': '4'},\n",
       " {'id': '962',\n",
       "  'firstname': 'Donna',\n",
       "  'surname': 'Strickland',\n",
       "  'motivation': '\"for their method of generating high-intensity, ultra-short optical pulses\"',\n",
       "  'share': '4'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data1['prizes'][0]['laureates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file2) as json_file:\n",
    "    json_data2 = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '103',\n",
       " 'firstname': 'Ben Roy',\n",
       " 'surname': 'Mottelson',\n",
       " 'born': '1926-07-09',\n",
       " 'died': '0000-00-00',\n",
       " 'bornCountry': 'USA',\n",
       " 'bornCountryCode': 'US',\n",
       " 'bornCity': 'Chicago, IL',\n",
       " 'gender': 'male',\n",
       " 'prizes': [{'year': '1975',\n",
       "   'category': 'physics',\n",
       "   'share': '3',\n",
       "   'motivation': '\"for the discovery of the connection between collective motion and particle motion in atomic nuclei and the development of the theory of the structure of the atomic nucleus based on this connection\"',\n",
       "   'affiliations': [{'name': 'Nordita',\n",
       "     'city': 'Copenhagen',\n",
       "     'country': 'Denmark'}]}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data2['laureates'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(file3) as json_file:\n",
    "#     json_data3 = json.load(json_file)\n",
    "\n",
    "# json_data3['countries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from pprint import pprint\n",
    "from graphgen import create_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_mapper = {\n",
    "    'nodes': [\n",
    "        {\n",
    "            'type': 'Affiliations',\n",
    "            'path': '/prizes/affiliations',\n",
    "            'key' : [\n",
    "                {'name': 'name', 'raw': '/prizes/affiliations/name'}\n",
    "            ],\n",
    "            'attributes': [\n",
    "                {'name': 'name',    'raw': '/prizes/affiliations/name'},\n",
    "                {'name': 'city',    'raw': '/prizes/affiliations/city'},\n",
    "                {'name': 'country', 'raw': '/prizes/affiliations/country'},\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'type': 'Prize',\n",
    "            'path': '/prizes',\n",
    "            'key' : [\n",
    "                {'name': 'category', 'raw': '/prizes/category'}\n",
    "            ],\n",
    "            'attributes': [\n",
    "                {'name': 'category', 'raw': '/prizes/category'},\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "edges_mapper = {\n",
    "    'edges': [\n",
    "        {\n",
    "            'type': 'Awarded',\n",
    "            'from': {\n",
    "                'type': 'Affiliations',\n",
    "                'path': '/prizes/affiliations',\n",
    "                'key' : [\n",
    "                    {'name': 'name', 'raw': '/prizes/affiliations/name'}\n",
    "                ]\n",
    "            },\n",
    "            'to'  : {\n",
    "                'type': 'Prize',\n",
    "                'path': '/prizes',\n",
    "                'key' : [\n",
    "                    {'name': 'category', 'raw': '/prizes/category'}\n",
    "                ]\n",
    "            },\n",
    "            'attributes': [\n",
    "                {'name': 'year', 'raw': '/prizes/year'}, \n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_node_attrs_from_json(jdata, type_path, attr_list):\n",
    "# #     print('>>> looking for:', type_path)\n",
    "# #     print('>>> looking for attrs:', attr_list)\n",
    "#     out = []\n",
    "\n",
    "#     # make sure our type_path end with '/'\n",
    "#     if type_path[-1] != '/':\n",
    "#         type_path += '/' \n",
    "    \n",
    "    \n",
    "#     def extract_data(jdata, cur_path = '/', cur_obj = None):\n",
    "#         if type(jdata) is dict:            \n",
    "#             if cur_path == type_path:\n",
    "# #                 print('<<< MATCHED_TYPE >>>')\n",
    "# #                 print('@path:', cur_path)\n",
    "#                 obj = {}\n",
    "#                 for a in jdata:\n",
    "#                     extract_data(jdata[a], cur_path + a + '/', obj)\n",
    "# #                 print('>>> got obj', obj)\n",
    "#                 out.append(obj)\n",
    "#             else:\n",
    "#                 for a in jdata:\n",
    "#                     extract_data(jdata[a], cur_path + a + '/')\n",
    "#         elif type(jdata) is list:\n",
    "#             for a in jdata:\n",
    "#                 extract_data(a, cur_path)\n",
    "#         else:\n",
    "# #             print('cur_path: {} - type_path: {}'.format(cur_path, type_path))\n",
    "#             if cur_obj != None and cur_path in attr_list:\n",
    "# #                 print('<<< MATCHED_ATTR >>>')\n",
    "#                 cur_obj[cur_path] = jdata\n",
    "    \n",
    "#     extract_data(jdata)\n",
    "#     return out\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_edge_attrs_from_json(jdata, src_type_path, dst_type_path, attr_list):\n",
    "# #     print('>>> looking for:', type_path)\n",
    "# #     print('>>> looking for attrs:', attr_dict)\n",
    "#     out = []\n",
    "\n",
    "#     # make sure our type_path end with '/'\n",
    "#     if src_type_path[-1] != '/':\n",
    "#         src_type_path += '/' \n",
    "    \n",
    "#     if dst_type_path[-1] != '/':\n",
    "#         dst_type_path += '/' \n",
    "        \n",
    "#     def extract_data(jdata, cur_path = '/', cur_obj = None, got_from = False, got_to = False):\n",
    "#         if type(jdata) is dict:            \n",
    "#             if cur_path == src_type_path or cur_path == dst_type_path:\n",
    "#                 if cur_path == src_type_path:\n",
    "#                     got_from = True\n",
    "#                 else:\n",
    "#                     got_to = True\n",
    "# #                 print('<<< MATCHED_TYPE >>>')\n",
    "# #                 print('@path:', cur_path)\n",
    "#                 obj = {}\n",
    "#                 if cur_obj != None: # we're still collecting\n",
    "#                     obj = cur_obj\n",
    "#                 for a in jdata:\n",
    "#                     extract_data(jdata[a], cur_path + a + '/', obj, got_from, got_to)\n",
    "# #                     print('>>> got edge data:', obj)\n",
    "# #                 print('got_from:', got_from, ' - got_to:', got_to)\n",
    "#                 if got_from and got_to:\n",
    "#                     out.append(obj)\n",
    "#                     got_from = got_to = False\n",
    "#             else:\n",
    "#                 for a in jdata:\n",
    "#                     extract_data(jdata[a], cur_path + a + '/', cur_obj, got_from, got_to)\n",
    "#         elif type(jdata) is list:\n",
    "#             for a in jdata:\n",
    "#                 extract_data(a, cur_path, cur_obj, got_from, got_to)\n",
    "#         else:\n",
    "# #             print('cur_path: {} - src_type_path: {} - dst_type_path: {}'.format(cur_path, \n",
    "# #                                                                                 src_type_path, dst_type_path))\n",
    "#             if cur_obj != None and cur_path in attr_list:\n",
    "# #                 print('<<< MATCHED_ATTR >>>')\n",
    "#                 cur_obj[cur_path] = jdata\n",
    "\n",
    "#     extract_data(jdata)\n",
    "#     return out\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_graph_nodes_from_json(graph, graph_mapper, data_provider, update = True):\n",
    "#     '''\n",
    "    \n",
    "#     params:\n",
    "#         graph: fully constructed graph object to add new nodes and edges to it.\n",
    "#         graph_mapper: dictionary describing the type of object to extract\n",
    "#         data_provider: json_data\n",
    "        \n",
    "#     return:\n",
    "#         constructured \"graph_type\" graph object based on the provided source data and according to \n",
    "#         the mapper schema description.\n",
    "#     '''\n",
    "\n",
    "#     assert (graph != None),\"Graph object wasn't constructed correctly\"\n",
    "#     # TBD... assert (isinstance(data_provider, pd.DataFrame)),\"The data provider should be a pandas DataFrame\"\n",
    "    \n",
    "#     # get list of node types and edge types\n",
    "#     node_types = []\n",
    "#     edge_types = []\n",
    "\n",
    "#     if 'nodes' in graph_mapper.keys():\n",
    "#         node_types = graph_mapper['nodes']\n",
    "#     if 'edges' in graph_mapper.keys():\n",
    "#         edge_types = graph_mapper['edges']\n",
    "\n",
    "#     raw_data = data_provider\n",
    "    \n",
    "# #     print(node_types)\n",
    "# #     print(edge_types)\n",
    "    \n",
    "#     for node_type in node_types:\n",
    "#         # TBD... assert check_attributes(node_type, raw_data, node_type['attributes'])\n",
    "       \n",
    "#         # TBD: Need to support multiple keys. For now we'll only have a single key for each record \n",
    "# #         print('node_type to process:', node_type)\n",
    "#         node_key = node_type['key'][0]\n",
    "#         key_name = node_key['name']\n",
    "#         key_raw_name = node_key['raw']\n",
    "\n",
    "#         attr_dict = {}\n",
    "#         for a in node_type['attributes']:\n",
    "#             raw_attr = a['raw']\n",
    "#             if raw_attr[-1] != '/':\n",
    "#                 raw_attr += '/'\n",
    "#             attr_dict[a['name']] = raw_attr\n",
    "        \n",
    "#         attr = dict()\n",
    "#         count = 0\n",
    "#         node_type_name = node_type['type']\n",
    "#         node_type_path = node_type['path']\n",
    "#         if node_type_path[-1] != '/':\n",
    "#             node_type_path += '/' \n",
    " \n",
    "#         # construct attribute mapping between raw_attrib_name -> attrib_name\n",
    "#         lookup_attr_list = []\n",
    "    \n",
    "#         for k, v in attr_dict.items():\n",
    "#             if v[-1] != '/':\n",
    "#                 v += '/'\n",
    "#             lookup_attr_list.append(v)\n",
    "        \n",
    "#         # make sure we have the key_raw_name in the list of attributes\n",
    "#         if key_raw_name[-1] != '/':\n",
    "#             key_raw_name += '/'\n",
    "#         if key_raw_name not in lookup_attr_list:\n",
    "#             lookup_attr_list.append(key_raw_name_path)\n",
    "# #         print('lookup_attr_list:', lookup_attr_list)\n",
    "        \n",
    "#         # iterate and collect.  \n",
    "#         for j in raw_data:\n",
    "# #             print('json>> ', j)\n",
    "#             jelem = extract_node_attrs_from_json(j, node_type_path, lookup_attr_list)\n",
    "#             if len(jelem) > 0:\n",
    "#                 for e in jelem:\n",
    "# #                     print('{} - type_found: {} - attr: {}'.format(count, node_type_name, e))\n",
    "#                     key_value = e[key_raw_name] if key_raw_name in e else 'UNKNOWN_'+str(count)\n",
    "#                     node_id = '{}_{}'.format(node_type_name, key_value)\n",
    "#                     if not update and graph.has_node(node_id):\n",
    "# #                         print('graph has node', node_id)\n",
    "#                         continue\n",
    "\n",
    "#                     attr['_type_'] = node_type_name\n",
    "#                     for k,v in attr_dict.items():\n",
    "#                         attr[k] = e[v] if v in e else ''\n",
    "# #                     print('>> adding node: ', node_id)\n",
    "#                     graph.add_node(node_id, **attr)\n",
    "#                     count += 1\n",
    "        \n",
    "#         print('type: {} - {}'.format(node_type_path, count))\n",
    "        \n",
    "#     return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_graph_edges_from_json(graph, graph_mapper, data_provider, update = True):\n",
    "#     '''\n",
    "    \n",
    "#     params:\n",
    "#         graph: fully constructed graph object to add new nodes and edges to it.\n",
    "#         graph_mapper: dictionary describing the type of object to extract\n",
    "#         data_provider: json_data\n",
    "        \n",
    "#     return:\n",
    "#         constructured \"graph_type\" graph object based on the provided source data and according to \n",
    "#         the mapper schema description.\n",
    "#     '''\n",
    "\n",
    "#     assert (graph != None),\"Graph object wasn't constructed correctly\"\n",
    "#     # TBD... assert (isinstance(data_provider, pd.DataFrame)),\"The data provider should be a pandas DataFrame\"\n",
    "    \n",
    "#     # get list of edge types and edge types\n",
    "#     edge_types = []\n",
    "\n",
    "#     if 'edges' in graph_mapper.keys():\n",
    "#         edge_types = graph_mapper['edges']\n",
    "\n",
    "#     raw_data = data_provider\n",
    "    \n",
    "# #     print(edge_types)\n",
    "#     for edge_type in edge_types:\n",
    "        \n",
    "#         # TBD... assert check_attributes(edge_type, raw_data, edge_type['attributes'])\n",
    "\n",
    "#         # TBD: Need to support multiple keys. For now we'll only have a single key for each record \n",
    "#         edge_type_name = edge_type['type']\n",
    "\n",
    "#         # source node metadata\n",
    "#         src_type_name = edge_type['from']['type']\n",
    "#         src_type_path = edge_type['from']['path']\n",
    "#         if src_type_path[-1] != '/':\n",
    "#             src_type_path += '/' \n",
    "\n",
    "#         src_key = edge_type['from']['key'][0]\n",
    "#         src_key_name = src_key['name']\n",
    "#         src_key_raw_name = src_key['raw']\n",
    "#         if src_key_raw_name[-1] != '/':\n",
    "#             src_key_raw_name += '/'\n",
    "        \n",
    "#         # destination node metadata\n",
    "#         dst_type_name = edge_type['to']['type']\n",
    "#         dst_type_path = edge_type['to']['path']\n",
    "#         if dst_type_path[-1] != '/':\n",
    "#             dst_type_path += '/' \n",
    "\n",
    "#         dst_key = edge_type['to']['key'][0]\n",
    "#         dst_key_name = dst_key['name']\n",
    "#         dst_key_raw_name = dst_key['raw']\n",
    "#         if dst_key_raw_name[-1] != '/':\n",
    "#             dst_key_raw_name += '/'\n",
    "    \n",
    "\n",
    "#         attr_dict = {}\n",
    "#         for a in edge_type['attributes']:\n",
    "#             v = a['raw']\n",
    "#             if v[-1] != '/':\n",
    "#                 v += '/'\n",
    "#             attr_dict[a['name']] = v\n",
    "            \n",
    "#         attr = dict()\n",
    "#         count = 0\n",
    " \n",
    "#         # construct attribute mapping between raw_attrib_name_path -> attrib_name\n",
    "#         lookup_attr_list = []\n",
    "    \n",
    "#         # TBD: review this code, not sure if it's necessary\n",
    "#         for k, v in attr_dict.items():\n",
    "#             lookup_attr_list.append(v)\n",
    "\n",
    "\n",
    "#         # make sure we have the src_key_raw_name in the list of attributes\n",
    "#         if src_key_raw_name not in lookup_attr_list:\n",
    "#             lookup_attr_list.append(src_key_raw_name)\n",
    "            \n",
    "#         # make sure we have the dst_key_raw_name in the list of attributes\n",
    "#         if dst_key_raw_name not in lookup_attr_list:\n",
    "#             lookup_attr_list.append(dst_key_raw_name)\n",
    "\n",
    "# #         print('lookup_attr_list:', lookup_attr_list)\n",
    "\n",
    "        \n",
    "#         # iterate and collect.  \n",
    "#         for j in raw_data:\n",
    "# #             print('json>> ', j)\n",
    "#             jelem = extract_edge_attrs_from_json(j, src_type_path, dst_type_path, lookup_attr_list)\n",
    "#             if len(jelem) > 0:\n",
    "#                 for e in jelem:\n",
    "# #                     print('{} - src: {} - dest: {} - attr: {}'.format(count, src_type_name, dst_type_name, e))\n",
    "#                     src_key_value = e[src_key_raw_name] if src_key_raw_name in e else 'UNKNOWN_'+str(count)\n",
    "#                     dst_key_value = e[dst_key_raw_name] if dst_key_raw_name in e else 'UNKNOWN_'+str(count)\n",
    "        \n",
    "#                     attr['_type_'] = edge_type_name\n",
    "#                     for k,v in attr_dict.items():\n",
    "#                         attr[k] = e[v] if v in e else ''\n",
    "#                     from_id = '{}_{}'.format(src_type_name, src_key_value)\n",
    "#                     to_id = '{}_{}'.format(dst_type_name, dst_key_value)\n",
    "# #                     print('adding edge from: {} -> to: {}, attr: {}'.format(from_id, to_id, attr))\n",
    "#                     graph.add_edge(from_id, to_id, **attr)\n",
    "                    \n",
    "#                     count += 1\n",
    "        \n",
    "#         print('type: {} -> {} - {}'.format(src_type_path, dst_type_path, count))\n",
    "       \n",
    "#     return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: /prizes/affiliations/ - 753\n",
      "type: /prizes/ - 941\n",
      "type: /prizes/affiliations/ -> /prizes/ - 753\n"
     ]
    }
   ],
   "source": [
    "g = nx.MultiDiGraph()\n",
    "\n",
    "g = create_graph(g, graph_mapper = nodes_mapper, \n",
    "                 data_provider = json_data2['laureates'])\n",
    "\n",
    "g = create_graph(g, graph_mapper = edges_mapper, \n",
    "                 data_provider = json_data2['laureates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "networkx.classes.multidigraph.MultiDiGraph"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.number_of_nodes(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "753"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.number_of_edges(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'born': '1907-10-02',\n",
      " 'bornCity': 'Glasgow',\n",
      " 'bornCountry': 'Scotland',\n",
      " 'bornCountryCode': 'GB',\n",
      " 'died': '1997-01-10',\n",
      " 'diedCity': 'Cambridge',\n",
      " 'diedCountry': 'United Kingdom',\n",
      " 'diedCountryCode': 'GB',\n",
      " 'firstname': 'Lord (Alexander R.)',\n",
      " 'gender': 'male',\n",
      " 'id': '221',\n",
      " 'prizes': [{'affiliations': [{'city': 'Cambridge',\n",
      "                               'country': 'United Kingdom',\n",
      "                               'name': 'University of Cambridge'}],\n",
      "             'category': 'chemistry',\n",
      "             'motivation': '\"for his work on nucleotides and nucleotide '\n",
      "                           'co-enzymes\"',\n",
      "             'share': '1',\n",
      "             'year': '1957'}],\n",
      " 'surname': 'Todd'}\n"
     ]
    }
   ],
   "source": [
    "pprint(json_data2['laureates'][216])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_type_': 'Affiliations', 'name': 'University of Cambridge', 'city': 'Cambridge', 'country': 'United Kingdom'}\n"
     ]
    }
   ],
   "source": [
    "print(g.node['Affiliations_University of Cambridge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_type_': 'Prize', 'category': 'chemistry'}\n",
      "{'_type_': 'Prize', 'category': 'physics'}\n"
     ]
    }
   ],
   "source": [
    "print(g.node['Prize_chemistry'])\n",
    "print(g.node['Prize_physics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'_type_': 'Awarded', 'year': '1922'},\n",
      " 1: {'_type_': 'Awarded', 'year': '1957'},\n",
      " 2: {'_type_': 'Awarded', 'year': '1958'}}\n"
     ]
    }
   ],
   "source": [
    "pprint(g.get_edge_data('Affiliations_University of Cambridge', 'Prize_chemistry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(g.get_edge_data('Prize_chemistry', 'Affiliations_University of Cambridge'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
