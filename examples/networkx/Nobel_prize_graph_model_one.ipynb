{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building graph using Nobel_prize JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "file1 = '../data/Nobel_prize.json'\n",
    "file2 = '../data/Nobel_laureate.json'\n",
    "file3 = '../data/Nobel_country.json' # this file has simple json structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file1) as json_file:\n",
    "    json_data1 = json.load(json_file)\n",
    "# json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.io.json import json_normalize\n",
    "\n",
    "# # this is not practical for the this json data\n",
    "# df = json_normalize(json_data1, 'prizes')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data1['prizes'][0]['laureates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file2) as json_file:\n",
    "    json_data2 = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data2['laureates'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(file3) as json_file:\n",
    "#     json_data3 = json.load(json_file)\n",
    "\n",
    "# json_data3['countries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from pprint import pprint\n",
    "from graphgen import create_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_mapper = {\n",
    "    'nodes': [\n",
    "        {\n",
    "            'type': 'Affiliations',\n",
    "            'path': '/prizes/affiliations',\n",
    "            'key' : [\n",
    "                {'name': 'name', 'raw': 'name'}\n",
    "            ],\n",
    "            'attributes': [\n",
    "                {'name': 'name',    'raw': 'name'},\n",
    "                {'name': 'city',    'raw': 'city'},\n",
    "                {'name': 'country', 'raw': 'country'},\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'type': 'Prize',\n",
    "            'path': '/prizes',\n",
    "            'key' : [\n",
    "                {'name': 'category', 'raw': 'category'}\n",
    "            ],\n",
    "            'attributes': [\n",
    "                {'name': 'category', 'raw': 'category'},\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "edges_mapper = {\n",
    "    'edges': [\n",
    "        {\n",
    "            'type': 'Awarded',\n",
    "            'from': {\n",
    "                'type': 'Affiliations',\n",
    "                'path': '/prizes/affiliations',\n",
    "                'key' : [\n",
    "                    {'name': 'name', 'raw': 'name'}\n",
    "                ]\n",
    "            },\n",
    "            'to'  : {\n",
    "                'type': 'Prize',\n",
    "                'path': '/prizes',\n",
    "                'key' : [\n",
    "                    {'name': 'category', 'raw': 'category'}\n",
    "                ]\n",
    "            },\n",
    "            'attributes': [\n",
    "                {'name': 'year',    'raw': 'year', 'path':'prizes/year'}, \n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_node_attrs_from_json(jdata, type_path, attr_dict):\n",
    "#     print('>>> looking for:', type_path)\n",
    "#     print('>>> looking for attrs:', attr_dict)\n",
    "    out = []\n",
    "\n",
    "    # make sure our type_path end with '/'\n",
    "    if type_path[-1] != '/':\n",
    "        type_path += '/' \n",
    "    \n",
    "    \n",
    "    def extract_data(jdata, cur_path = '/', cur_obj = None):\n",
    "        if type(jdata) is dict:            \n",
    "            if cur_path == type_path:\n",
    "#                 print('<<< MATCHED_TYPE >>>')\n",
    "#                 print('@path:', cur_path)\n",
    "                obj = {}\n",
    "                for a in jdata:\n",
    "                    extract_data(jdata[a], cur_path + a + '/', obj)\n",
    "#                 print('>>> got obj', obj)\n",
    "                out.append(obj)\n",
    "            else:\n",
    "                for a in jdata:\n",
    "                    extract_data(jdata[a], cur_path + a + '/')\n",
    "        elif type(jdata) is list:\n",
    "            for a in jdata:\n",
    "                extract_data(a, cur_path)\n",
    "        else:\n",
    "#             print('cur_path: {} - type_path: {}'.format(cur_path, type_path))\n",
    "            if cur_obj != None and cur_path in attr_dict.keys():\n",
    "#                 print('<<< MATCHED_ATTR >>>')\n",
    "                cur_obj[attr_dict[cur_path]] = jdata\n",
    "    \n",
    "    extract_data(jdata)\n",
    "    return out\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_edge_attrs_from_json(jdata, src_type_path, dst_type_path, attr_dict):\n",
    "#     print('>>> looking for:', type_path)\n",
    "#     print('>>> looking for attrs:', attr_dict)\n",
    "    out = []\n",
    "\n",
    "    # make sure our type_path end with '/'\n",
    "    if src_type_path[-1] != '/':\n",
    "        src_type_path += '/' \n",
    "    \n",
    "    if dst_type_path[-1] != '/':\n",
    "        dst_type_path += '/' \n",
    "    \n",
    "    \n",
    "    def extract_data(jdata, cur_path = '/', cur_obj = None):\n",
    "        if type(jdata) is dict:            \n",
    "            if cur_path == src_type_path or cur_path == dst_type_path:\n",
    "                print('<<< MATCHED_TYPE >>>')\n",
    "                print('@path:', cur_path)\n",
    "                obj = {}\n",
    "                for a in jdata:\n",
    "                    extract_data(jdata[a], cur_path + a + '/', obj)\n",
    "                    print('>>> got edge data:', obj)\n",
    "                out.append(obj)\n",
    "            else:\n",
    "                for a in jdata:\n",
    "                    extract_data(jdata[a], cur_path + a + '/')\n",
    "        elif type(jdata) is list:\n",
    "            for a in jdata:\n",
    "                extract_data(a, cur_path)\n",
    "        else:\n",
    "            print('cur_path: {} - type_path: {}'.format(cur_path, type_path))\n",
    "            if cur_obj != None and cur_path in attr_dict.keys():\n",
    "                print('<<< MATCHED_ATTR >>>')\n",
    "                cur_obj[attr_dict[cur_path]] = jdata\n",
    "    \n",
    "    extract_data(jdata)\n",
    "    return out\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_nodes_from_json(graph, graph_mapper, data_provider, update = True):\n",
    "    '''\n",
    "    \n",
    "    params:\n",
    "        graph: fully constructed graph object to add new nodes and edges to it.\n",
    "        graph_mapper: dictionary describing the type of object to extract\n",
    "        data_provider: json_data\n",
    "        \n",
    "    return:\n",
    "        constructured \"graph_type\" graph object based on the provided source data and according to \n",
    "        the mapper schema description.\n",
    "    '''\n",
    "\n",
    "    assert (graph != None),\"Graph object wasn't constructed correctly\"\n",
    "    # TBD... assert (isinstance(data_provider, pd.DataFrame)),\"The data provider should be a pandas DataFrame\"\n",
    "    \n",
    "    # get list of node types and edge types\n",
    "    node_types = []\n",
    "    edge_types = []\n",
    "\n",
    "    if 'nodes' in graph_mapper.keys():\n",
    "        node_types = graph_mapper['nodes']\n",
    "    if 'edges' in graph_mapper.keys():\n",
    "        edge_types = graph_mapper['edges']\n",
    "\n",
    "    raw_data = data_provider\n",
    "    \n",
    "#     print(node_types)\n",
    "#     print(edge_types)\n",
    "    \n",
    "    for node_type in node_types:\n",
    "        # TBD... assert check_attributes(node_type, raw_data, node_type['attributes'])\n",
    "       \n",
    "        # TBD: Need to support multiple keys. For now we'll only have a single key for each record \n",
    "        node_key = node_type['key'][0]\n",
    "        key_name = node_key['name']\n",
    "        key_raw_name = node_key['raw']\n",
    "\n",
    "        attr_dict = {}\n",
    "        for a in node_type['attributes']:\n",
    "            attr_dict[a['name']] = a['raw']\n",
    "        \n",
    "        attr = dict()\n",
    "        count = 0\n",
    "        node_type_name = node_type['type']\n",
    "        node_type_path = node_type['path']\n",
    " \n",
    "        # construct attribute mapping between type_path+raw_attrib_name -> attrib_name\n",
    "        lookup_attr_dict = {}\n",
    "        if node_type_path[:-1] != '/':\n",
    "            node_type_path += '/' \n",
    "    \n",
    "        for k, v in attr_dict.items():\n",
    "            lookup_attr_dict[node_type_path + v + '/'] = k\n",
    "\n",
    "        # iterate and collect.  \n",
    "        for j in raw_data:\n",
    "#             print('json>> ', j)\n",
    "            jelem = extract_node_attrs_from_json(j, node_type_path, lookup_attr_dict)\n",
    "            if len(jelem) > 0:\n",
    "                for e in jelem:\n",
    "#                     print('{} - type_found: {} - attr: {}'.format(count, node_type_name, e))\n",
    "                    key_value = e[key_raw_name] if key_raw_name in e else 'UNKNOWN_'+str(count)\n",
    "                    node_id = '{}_{}'.format(node_type_name, key_value)\n",
    "                    if not update and graph.has_node(node_id):\n",
    "                        continue\n",
    "\n",
    "                    attr['_type_'] = node_type_name\n",
    "                    for k,v in attr_dict.items():\n",
    "                        attr[k] = e[v] if v in e else ''\n",
    "                    graph.add_node(node_id, **attr)\n",
    "                count += 1\n",
    "        \n",
    "        print(count)\n",
    "        \n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_edges_from_json(graph, graph_mapper, data_provider, update = True):\n",
    "    '''\n",
    "    \n",
    "    params:\n",
    "        graph: fully constructed graph object to add new nodes and edges to it.\n",
    "        graph_mapper: dictionary describing the type of object to extract\n",
    "        data_provider: json_data\n",
    "        \n",
    "    return:\n",
    "        constructured \"graph_type\" graph object based on the provided source data and according to \n",
    "        the mapper schema description.\n",
    "    '''\n",
    "\n",
    "    assert (graph != None),\"Graph object wasn't constructed correctly\"\n",
    "    # TBD... assert (isinstance(data_provider, pd.DataFrame)),\"The data provider should be a pandas DataFrame\"\n",
    "    \n",
    "    # get list of edge types and edge types\n",
    "    edge_types = []\n",
    "\n",
    "    if 'edges' in graph_mapper.keys():\n",
    "        edge_types = graph_mapper['edges']\n",
    "\n",
    "    raw_data = data_provider\n",
    "    \n",
    "#     print(edge_types)\n",
    "    for edge_type in edge_types:\n",
    "        \n",
    "        # TBD... assert check_attributes(edge_type, raw_data, edge_type['attributes'])\n",
    "\n",
    "        # TBD: Need to support multiple keys. For now we'll only have a single key for each record \n",
    "        edge_type_name = edge_type['type']\n",
    "\n",
    "        # source node metadata\n",
    "        src_type_name = edge_type['from']['type']\n",
    "        src_type_path = edge_type['from']['path']\n",
    "        if src_type_path[:-1] != '/':\n",
    "            src_type_path += '/' \n",
    "\n",
    "        src_key = edge_type['from']['key']\n",
    "        src_key_name = src_key['name']\n",
    "        src_key_raw_name = src_key['raw']\n",
    "        \n",
    "        # destination node metadata\n",
    "        dst_type_name = edge_type['to']['type']\n",
    "        dst_type_path = edge_type['to']['path']\n",
    "        if dst_type_path[:-1] != '/':\n",
    "            dst_type_path += '/' \n",
    "\n",
    "        dst_key = edge_type['to']['key']\n",
    "        dst_key_name = src_key['name']\n",
    "        dst_key_raw_name = src_key['raw']\n",
    "    \n",
    "\n",
    "        attr_dict = {}\n",
    "        for a in node_type['attributes']:\n",
    "            attr_dict[a['name']] = a['path']\n",
    "        \n",
    "        attr = dict()\n",
    "        count = 0\n",
    " \n",
    "        # construct attribute mapping between raw_attrib_name_path -> attrib_name\n",
    "        lookup_attr_dict = {}\n",
    "    \n",
    "        for k, v in attr_dict.items():\n",
    "            if v[:-1] != '/':\n",
    "                v += '/'\n",
    "            lookup_attr_dict[v] = k\n",
    "\n",
    "        # iterate and collect.  \n",
    "        for j in raw_data:\n",
    "#             print('json>> ', j)\n",
    "            jelem = extract_edge_attrs_from_json(j, src_type_path, dst_type_path, lookup_attr_dict)\n",
    "            if len(jelem) > 0:\n",
    "                for e in jelem:\n",
    "                    print('{} - src: {} - dest: {} - attr: {}'.format(count, src_type_name, dst_type_name, e))\n",
    "                    src_key_value = e[src_key_raw_name] if src_key_raw_name in e else 'UNKNOWN_'+str(count)\n",
    "                    dst_key_value = e[dst_key_raw_name] if dst_key_raw_name in e else 'UNKNOWN_'+str(count)\n",
    "        \n",
    "                    attr['_type_'] = edge_type_name\n",
    "                    for k,v in attr_dict.items():\n",
    "                        attr[k] = e[v] if v in e else ''\n",
    "                    graph.add_node(node_id, **attr)\n",
    "                    from_id = '{}_{}'.format(src_type_name, src_key_value)\n",
    "                    to_id = '{}_{}'.format(dst_type_name, dst_key_value)\n",
    "                    graph.add_edge(from_id, to_id, **attr)\n",
    "                    \n",
    "                count += 1\n",
    "        \n",
    "        print(count)\n",
    "        \n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.MultiDiGraph()\n",
    "\n",
    "g = create_graph_nodes_from_json(g, graph_mapper = nodes_mapper, \n",
    "                 data_provider = json_data2['laureates'])\n",
    "\n",
    "# g = create_graph(g, graph_mapper = edges_mapper, \n",
    "#                  data_provider = trips_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.number_of_nodes(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(json_data2['laureates'][216])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nx.number_of_edges(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g.node['Station_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(g.get_edge_data('Station_2', 'Station_16'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
